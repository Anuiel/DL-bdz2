{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from pathlib import Path\n",
    "from config import Config\n",
    "\n",
    "config = Config(\n",
    "    path_to_data=Path('/home/anuiel/Remote/Anuiel/dl-bdz2/data')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38931, 26346)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import Multi228k\n",
    "from tokenizer import TextTransform, PAD_IDX\n",
    "\n",
    "train_dataset = Multi228k(config.path_to_data, 'train', config.source_language, config.target_language)\n",
    "val_dataset = Multi228k(config.path_to_data, 'val', config.source_language, config.target_language)\n",
    "test_dataset = Multi228k(config.path_to_data, 'test1', config.source_language, config.target_language)\n",
    "\n",
    "text_transform = TextTransform(config.path_to_data, config.source_language, config.target_language)\n",
    "source_vocab_size = len(text_transform.vocab_transform[config.source_language])\n",
    "target_vocab_size = len(text_transform.vocab_transform[config.target_language])\n",
    "source_vocab_size, target_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuiel/Remote/Anuiel/dl-bdz2/env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from model import load_model\n",
    "\n",
    "model = load_model(config, source_vocab_size, target_vocab_size, Path('/home/anuiel/Remote/Anuiel/dl-bdz2/data/models/k9gjga8c.pth')).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'diesen morgen werde ich niemals vergessen .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import BOS_IDX, EOS_IDX\n",
    "from train import generate_square_subsequent_mask\n",
    "from inference import greedy_decode\n",
    "from beam_search import beam_search\n",
    "\n",
    "\n",
    "def translate(\n",
    "    model,\n",
    "    src_sentence: str,\n",
    "    text_transform: TextTransform,\n",
    "    config: Config\n",
    "):\n",
    "    model.eval()\n",
    "    src = text_transform.text_transform[config.source_language](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = torch.zeros(num_tokens, num_tokens, dtype=torch.bool)\n",
    "    # tgt_tokens: Tensor = greedy_decode(\n",
    "    #     model, src, src_mask, max_len=10, start_symbol=BOS_IDX, device=config.device\n",
    "    # ).flatten()\n",
    "    tgt_tokens: Tensor = beam_search(\n",
    "        model,\n",
    "        width=1,\n",
    "        length_penalty=2,\n",
    "        temp=1,\n",
    "        src=src,\n",
    "        src_mask=src_mask,\n",
    "        max_len=num_tokens+5,\n",
    "        start_symbol=BOS_IDX,\n",
    "        device=config.device\n",
    "    )\n",
    "    return tgt_tokens\n",
    "    # return \" \".join(\n",
    "    #     text_transform.vocab_transform[config.target_language].lookup_tokens(list(tgt_tokens.cpu().numpy()))\n",
    "    # ).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"<unk>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> that morning , i 'll never forget this morning . <eos>\n"
     ]
    }
   ],
   "source": [
    "for score, t in translate(model, s, text_transform, config):\n",
    "    ss = \" \".join(\n",
    "        text_transform.vocab_transform[config.target_language].lookup_tokens(list(t.cpu().numpy()))\n",
    "    )\n",
    "    print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
